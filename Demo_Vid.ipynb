{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rET4bXRp8mm6",
        "L43TF_uc87We",
        "kiMnsuVc9OSZ",
        "D1PLjoEK7y0u"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPwf8eyYM459qJaSqm+m7sK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Victoooooor/ErgoChairML/blob/main/Demo_Vid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Environment"
      ],
      "metadata": {
        "id": "rET4bXRp8mm6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "id": "LamhSqRnZTBY",
        "outputId": "4f439358-a923-4cbe-f2e4-e1ababfee4d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libmagic-dev is already the newest version (1:5.32-2ubuntu0.4).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "Collecting git+https://github.com/Victoooooor/ErgoChairML.git\n",
            "  Cloning https://github.com/Victoooooor/ErgoChairML.git to /tmp/pip-req-build-qh_mu7gq\n",
            "  Running command git clone -q https://github.com/Victoooooor/ErgoChairML.git /tmp/pip-req-build-qh_mu7gq\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (1.19.5)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (0.2.9)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (2.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (4.62.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (7.1.2)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (0.4.25)\n",
            "Requirement already satisfied: progressbar in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (2.5)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (5.5.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (4.1.2.30)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from ErgoChairML==0.0.2) (2.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug->ErgoChairML==0.0.2) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug->ErgoChairML==0.0.2) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug->ErgoChairML==0.0.2) (0.18.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug->ErgoChairML==0.0.2) (2.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->ErgoChairML==0.0.2) (1.8.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug->ErgoChairML==0.0.2) (1.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug->ErgoChairML==0.0.2) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug->ErgoChairML==0.0.2) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ErgoChairML==0.0.2) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ErgoChairML==0.0.2) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ErgoChairML==0.0.2) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ErgoChairML==0.0.2) (0.11.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->ErgoChairML==0.0.2) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->ErgoChairML==0.0.2) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->ErgoChairML==0.0.2) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->ErgoChairML==0.0.2) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->ErgoChairML==0.0.2) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->ErgoChairML==0.0.2) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->ErgoChairML==0.0.2) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->ErgoChairML==0.0.2) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->ErgoChairML==0.0.2) (0.2.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ErgoChairML==0.0.2) (2018.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->ErgoChairML==0.0.2) (0.7.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (3.10.0.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (13.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (1.13.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (1.43.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (0.24.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (2.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (2.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (0.37.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ErgoChairML==0.0.2) (1.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->ErgoChairML==0.0.2) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->ErgoChairML==0.0.2) (3.2.0)\n",
            "Requirement already satisfied: tensorflow-io in /usr/local/lib/python3.7/dist-packages (0.24.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.24.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-io) (0.24.0)\n",
            "deb http://packages.cloud.google.com/apt gcsfuse-bionic main\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2537  100  2537    0     0   103k      0 --:--:-- --:--:-- --:--:--  103k\n",
            "OK\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:2 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 256 kB in 1s (222 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "gcsfuse is already the newest version (0.39.2).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!apt-get install libmagic-dev\n",
        "!pip install git+https://github.com/Victoooooor/ErgoChairML.git\n",
        "!pip install -q imageio\n",
        "!pip install tensorflow-io\n",
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!sudo apt-get -y -q update\n",
        "!sudo apt-get -y -q install gcsfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOGIN"
      ],
      "metadata": {
        "id": "RCusvyFrlmDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "JH6l8bL_lkLg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load trained model"
      ],
      "metadata": {
        "id": "L43TF_uc87We"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bucket_name = 'ergo_chair_ml'\n",
        "!gsutil -m cp -r gs://{bucket_name}/* ./"
      ],
      "metadata": {
        "id": "5r70Nv83cpHg",
        "outputId": "404f8432-f986-4f56-c5f6-f0f3b3677863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://ergo_chair_ml/masked_checkpoints/ckpt-8.index...\n",
            "/ [0 files][    0.0 B/ 16.1 KiB]                                                \rCopying gs://ergo_chair_ml/masked_checkpoints/ckpt-9.data-00000-of-00001...\n",
            "/ [0 files][    0.0 B/654.5 MiB]                                                \rCopying gs://ergo_chair_ml/masked_checkpoints/checkpoint...\n",
            "Copying gs://ergo_chair_ml/movenet_thunder.tflite...\n",
            "/ [0 files][    0.0 B/654.5 MiB]                                                \r/ [0 files][    0.0 B/666.5 MiB]                                                \rCopying gs://ergo_chair_ml/masked_checkpoints/ckpt-7.data-00000-of-00001...\n",
            "/ [0 files][    0.0 B/  1.3 GiB]                                                \rCopying gs://ergo_chair_ml/masked_checkpoints/ckpt-8.data-00000-of-00001...\n",
            "/ [0 files][    0.0 B/  1.9 GiB]                                                \rCopying gs://ergo_chair_ml/masked_checkpoints/ckpt-7.index...\n",
            "/ [0 files][    0.0 B/  1.9 GiB]                                                \rCopying gs://ergo_chair_ml/skeleton_checkpoints/ckpt-7.data-00000-of-00001...\n",
            "/ [0/15 files][    0.0 B/  3.8 GiB]   0% Done                                   \rCopying gs://ergo_chair_ml/skeleton_checkpoints/ckpt-5.index...\n",
            "/ [0/15 files][    0.0 B/  3.8 GiB]   0% Done                                   \rCopying gs://ergo_chair_ml/skeleton_checkpoints/ckpt-6.index...\n",
            "Copying gs://ergo_chair_ml/skeleton_checkpoints/ckpt-6.data-00000-of-00001...\n",
            "/ [0/15 files][    0.0 B/  3.8 GiB]   0% Done                                   \r/ [0/15 files][    0.0 B/  3.8 GiB]   0% Done                                   \rCopying gs://ergo_chair_ml/masked_checkpoints/ckpt-9.index...\n",
            "/ [0/15 files][    0.0 B/  3.8 GiB]   0% Done                                   \rCopying gs://ergo_chair_ml/skeleton_checkpoints/ckpt-5.data-00000-of-00001...\n",
            "/ [0/15 files][    0.0 B/  3.8 GiB]   0% Done                                   \rCopying gs://ergo_chair_ml/skeleton_checkpoints/checkpoint...\n",
            "Copying gs://ergo_chair_ml/skeleton_checkpoints/ckpt-7.index...\n",
            "- [15/15 files][  3.8 GiB/  3.8 GiB] 100% Done  87.6 MiB/s ETA 00:00:00         \n",
            "Operation completed over 15 objects/3.8 GiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init"
      ],
      "metadata": {
        "id": "kiMnsuVc9OSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gen_chair import pix2pix\n",
        "\n",
        "from gen_chair import coco\n",
        "from gen_chair.gen_multi import Preprocess\n",
        "from gen_chair import pix2pix\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "import tqdm\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageSequence\n",
        "import numpy as np\n",
        "import tensorflow_io as tfio \n",
        "\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "\n",
        "class InferenceConfig(coco.CocoConfig):\n",
        "  # Set batch size to 1 since we'll be running inference on\n",
        "  # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1\n",
        "\n",
        "def Infer(preproc, generator, origin, masked = True):\n",
        "\n",
        "  pre = preproc(origin)\n",
        "  if type(pre) is tuple:\n",
        "      if masked:\n",
        "        seg = pre[0]\n",
        "      else:\n",
        "        seg = pre[1]\n",
        "  else:\n",
        "      seg = None\n",
        "  origin = tf.cast(tf.image.resize_with_pad(origin, 256, 256), dtype=tf.int32)\n",
        "\n",
        "  if seg is not None:\n",
        "    seg  = tf.keras.preprocessing.image.img_to_array(seg)\n",
        "\n",
        "  else:\n",
        "    seg = origin\n",
        "\n",
        "  seg = tf.expand_dims(seg, axis=0)\n",
        "  seg = tf.cast(tf.image.resize_with_pad(seg, 256, 256), dtype=tf.int32)\n",
        "\n",
        "  gen = generator(seg ,training=True)\n",
        "  gen = tf.keras.utils.array_to_img(gen[0])\n",
        "\n",
        "  seg = tf.keras.utils.array_to_img(seg[0])\n",
        "\n",
        "  origin = tf.keras.utils.array_to_img(origin)\n",
        "  dst = Image.new('RGB', (origin.width + seg.width + gen.width, origin.height))\n",
        "  dst.paste(origin, (0, 0))\n",
        "  dst.paste(seg, (origin.width, 0))\n",
        "  dst.paste(gen, (origin.width+seg.width, 0))\n",
        "  return dst\n",
        "\n",
        "imgdr = 'data/'\n",
        "\n",
        "prep = Preprocess(InferenceConfig)\n",
        "\n",
        "cpdir_mask = 'masked_checkpoints'\n",
        "masked = pix2pix(cpdir_mask)\n",
        "masked.loadcp()\n",
        "\n",
        "cpdir_ske = 'skeleton_checkpoints'\n",
        "skeleton = pix2pix(cpdir_ske)\n",
        "skeleton.loadcp()"
      ],
      "metadata": {
        "id": "YUiUuoMabuPh",
        "outputId": "0b94ba21-6257-4458-96e2-1a1383462800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pretrained model to /content/mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                93\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           coco\n",
            "NUM_CLASSES                    81\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1000\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored from masked_checkpoints/ckpt-9\n",
            "Restored from skeleton_checkpoints/ckpt-7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Input"
      ],
      "metadata": {
        "id": "EbKw4Q7s4VFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tab under will prompt to upload local files,\n",
        "Support Format:\n",
        "  most image format\n",
        "  MP4, AVI\n",
        "  zip"
      ],
      "metadata": {
        "id": "F0k0dfCC4Z48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  # get photo data\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # get OpenCV format image\n",
        "  img = js_to_image(data) \n",
        "  # grayscale img\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  print(gray.shape)\n",
        "  # get face bounding box coordinates using Haar Cascade\n",
        "  faces = face_cascade.detectMultiScale(gray)\n",
        "  # draw face bounding box on image\n",
        "  for (x,y,w,h) in faces:\n",
        "      img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "  # save image\n",
        "  cv2.imwrite(filename, img)\n",
        "\n",
        "  return filename\n",
        "\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 768, 256);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '800px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 768; //video.videoWidth;\n",
        "      captureCanvas.height = 256; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "MMHspTs_3piu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "    img = tf.convert_to_tensor(img)\n",
        "    mframe = Infer(prep.img_seg, masked.generator, img, True)\n",
        "    sframe = Infer(prep.img_seg, skeleton.generator, img, False)\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.full([512, 768, 4], 255, dtype=np.uint8)\n",
        "    bbox_array[:256, :,:3] = mframe\n",
        "    bbox_array[256:, : , :3] = sframe\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "id": "xhR4fIhZ3sqV",
        "outputId": "73361ce1-6aaa-4802-b6fe-46aa5ceb0335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 768, 256);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '800px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 768; //video.videoWidth;\n",
              "      captureCanvas.height = 256; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711F6C90> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDB3E3245D0>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711FBB90> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7095AC50>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711B7B10> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDB3E325A90>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA709781D0> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711AA890>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711C8450> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71215590>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71175450> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711F6110>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA70972BD0> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711BABD0>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71154D10> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711E1D10>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7114A410> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71124190>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDB3E325A90> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA70972150>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7118CBD0> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA70999090>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDB3E2AE0D0> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711E4850>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDB3E2AE0D0> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711727D0>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA70982A50> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711905D0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "None Detected\n",
            "None Detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710F7F90> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA709C5B90>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710FF550> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7110E7D0>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA709A2350> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA709A2810>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710DC290> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711E4C50>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "None Detected\n",
            "None Detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA709A0050> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7118AD90>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711E4C50> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711F6810>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "None Detected\n",
            "None Detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FD8E0E24DD0> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA70993450>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA709B3450> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FD8E0E24DD0>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71061150> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7105B150>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710C2910> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7119E4D0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA709D42D0> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710FD510>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7119EB90> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711AAC90>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "None Detected\n",
            "None Detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA70990990> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7116DB50>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA70999550> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711C9CD0>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7109E0D0> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA70972AD0>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7108D0D0> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71068410>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711F1710> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711C15D0>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710C2D50> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71190ED0>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710DC450> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71114150>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71095610> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710B4250>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA711C1290> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA709AA3D0>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710B4250> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA709AA390>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71048D90> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71020C90>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71035350> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71180A10>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDB3E2C1D10> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71172890>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FD8E167A8D0> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71074BD0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA709994D0> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FD8E167A8D0>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7111B810> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA70993410>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710B4710> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710FDA10>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7116D750> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA70FDCC90>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA709B3D50> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA710B4710>\n",
            "<PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA7116D090> <PIL.Image.Image image mode=RGB size=768x256 at 0x7FDA71215650>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n",
            "None Detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process & Download"
      ],
      "metadata": {
        "id": "D1PLjoEK7y0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_names = sorted([n for n in os.listdir(imgdr) if not n.startswith('.')])\n",
        "\n",
        "outdr1 = 'out_seg'\n",
        "!mkdir -p {outdr1}\n",
        "outdr2 = 'out_ske'\n",
        "!mkdir -p {outdr2}\n",
        "audiofile = '_sound.mp3'\n",
        "\n",
        "for image_name in tqdm.tqdm(image_names):\n",
        "  image_path = os.path.join(imgdr, image_name)\n",
        "  #loop through for gif\n",
        "  if image_path.endswith('.gif'):\n",
        "    image = Image.open(image_path)\n",
        "    image.seek(0)\n",
        "    mask_frames = []\n",
        "    ske_frames = []\n",
        "    durations = []\n",
        "    for frame in ImageSequence.Iterator(image):\n",
        "        durations.append(image.info['duration'])\n",
        "        frame = frame.convert('RGB')\n",
        "        tfframe = tf.convert_to_tensor(np.array(frame))\n",
        "        mframe = Infer(prep.img_seg, masked.generator, tfframe, True)\n",
        "        sframe = Infer(prep.img_seg, skeleton.generator, tfframe, False)\n",
        "\n",
        "        mask_frames.append(mframe)\n",
        "        ske_frames.append(sframe)\n",
        "    mask_frames[0].save(os.path.join(outdr1, image_name),\n",
        "        save_all=True,\n",
        "        append_images=mask_frames[1:],\n",
        "        duration=durations,\n",
        "        loop=0)\n",
        "    ske_frames[0].save(os.path.join(outdr2, image_name),\n",
        "        save_all=True,\n",
        "        append_images=ske_frames[1:],\n",
        "        duration=durations,\n",
        "        loop=0)\n",
        "  #simple image process\n",
        "  elif image_path.endswith(img_suffix):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.io.decode_image(image)\n",
        "    channel = image.shape[-1]\n",
        "    if channel == 1:\n",
        "      image = tf.image.grayscale_to_rgb(image)\n",
        "    elif channel == 4:\n",
        "      image = tfio.experimental.color.rgba_to_rgb(image)\n",
        "    elif channel == 2:\n",
        "      print(\"Stop, Get Some Help, Only RGB, RGBA, Greyscale\")\n",
        "      continue\n",
        "    maskout = Infer(prep.img_seg, masked.generator, image, True)\n",
        "    skeletonout = Infer(prep.img_seg, skeleton.generator, image, False)\n",
        "    maskout.save(os.path.join(outdr1, image_name))\n",
        "    skeletonout.save(os.path.join(outdr2, image_name))\n",
        "  #loop through video frames\n",
        "  elif image_path.endswith(vid_suffix):\n",
        "    print('video',image_path)\n",
        "    video = cv2.VideoCapture(image_path)\n",
        "    if not video.isOpened():\n",
        "      print('video does not exist')\n",
        "      continue\n",
        "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "    frame_num = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_width = 256*3\n",
        "    frame_height = 256\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    name1 = os.path.join(outdr1, image_name)\n",
        "    name2 = os.path.join(outdr2, image_name)\n",
        "    video_writer1 = cv2.VideoWriter(name1,fourcc,fps,(frame_width,frame_height))\n",
        "    video_writer2 = cv2.VideoWriter(name2,fourcc,fps,(frame_width,frame_height))\n",
        "    print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "    counter =0\n",
        "    while True:\n",
        "      ret, frame = video.read()\n",
        "      if ret == True:\n",
        "          tfframe= tf.convert_to_tensor(frame)\n",
        "          mframe = Infer(prep.img_seg, masked.generator, tfframe, True)\n",
        "          sframe = Infer(prep.img_seg, skeleton.generator, tfframe, False)\n",
        "          m_cv2 = cv2.cvtColor(np.array(mframe), cv2.COLOR_RGB2BGR)\n",
        "          s_cv2 = cv2.cvtColor(np.array(sframe), cv2.COLOR_RGB2BGR)\n",
        "          video_writer1.write(m_cv2)\n",
        "          video_writer2.write(s_cv2)\n",
        "          counter +=1\n",
        "      if ret == False:\n",
        "          break\n",
        "    video.release()\n",
        "    video_writer1.release()\n",
        "    video_writer2.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "!zip -r file.zip {outdr1} {outdr2}\n",
        "files.download('file.zip')"
      ],
      "metadata": {
        "id": "FzS2ywyItq4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf {outdr1} {outdr2} {imgdr}"
      ],
      "metadata": {
        "id": "hxfIuAKuVQA3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}