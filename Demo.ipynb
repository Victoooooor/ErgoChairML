{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rET4bXRp8mm6",
        "L43TF_uc87We",
        "kiMnsuVc9OSZ",
        "D1PLjoEK7y0u"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNPWnO2QoH5/sYZrcKgtxaF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Victoooooor/ErgoChairML/blob/main/Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Environment"
      ],
      "metadata": {
        "id": "rET4bXRp8mm6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LamhSqRnZTBY"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!apt-get install libmagic-dev\n",
        "!pip install git+https://github.com/Victoooooor/ErgoChairML.git\n",
        "!pip install -q imageio\n",
        "!pip install tensorflow-io\n",
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!sudo apt-get -y -q update\n",
        "!sudo apt-get -y -q install gcsfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOGIN"
      ],
      "metadata": {
        "id": "RCusvyFrlmDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "JH6l8bL_lkLg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load trained model"
      ],
      "metadata": {
        "id": "L43TF_uc87We"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bucket_name = 'ergo_chair_ml'\n",
        "!gsutil -m cp -r gs://{bucket_name}/* ./"
      ],
      "metadata": {
        "id": "5r70Nv83cpHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init"
      ],
      "metadata": {
        "id": "kiMnsuVc9OSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gen_chair import pix2pix\n",
        "\n",
        "from gen_chair import coco\n",
        "from gen_chair.gen_multi import Preprocess\n",
        "from gen_chair import pix2pix\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "import tqdm\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageSequence\n",
        "import numpy as np\n",
        "import tensorflow_io as tfio \n",
        "\n",
        "class InferenceConfig(coco.CocoConfig):\n",
        "  # Set batch size to 1 since we'll be running inference on\n",
        "  # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1\n",
        "\n",
        "def Infer(preproc, generator, origin, masked = True):\n",
        "\n",
        "  pre = preproc(origin)\n",
        "  if type(pre) is tuple:\n",
        "      if masked:\n",
        "        seg = pre[0]\n",
        "      else:\n",
        "        seg = pre[1]\n",
        "  else:\n",
        "      seg = None\n",
        "  origin = tf.cast(tf.image.resize_with_pad(origin, 256, 256), dtype=tf.int32)\n",
        "\n",
        "  if seg is not None:\n",
        "    seg  = tf.keras.preprocessing.image.img_to_array(seg)\n",
        "\n",
        "  else:\n",
        "    seg = origin\n",
        "\n",
        "  seg = tf.expand_dims(seg, axis=0)\n",
        "  seg = tf.cast(tf.image.resize_with_pad(seg, 256, 256), dtype=tf.int32)\n",
        "\n",
        "  gen = generator(seg ,training=True)\n",
        "  gen = tf.keras.utils.array_to_img(gen[0])\n",
        "\n",
        "  seg = tf.keras.utils.array_to_img(seg[0])\n",
        "\n",
        "  origin = tf.keras.utils.array_to_img(origin)\n",
        "  dst = Image.new('RGB', (origin.width + seg.width + gen.width, origin.height))\n",
        "  dst.paste(origin, (0, 0))\n",
        "  dst.paste(seg, (origin.width, 0))\n",
        "  dst.paste(gen, (origin.width+seg.width, 0))\n",
        "  return dst\n",
        "\n",
        "imgdr = 'data/'\n",
        "\n",
        "prep = Preprocess(InferenceConfig)\n",
        "\n",
        "cpdir_mask = 'masked_checkpoints'\n",
        "masked = pix2pix(cpdir_mask)\n",
        "masked.loadcp()\n",
        "\n",
        "cpdir_ske = 'skeleton_checkpoints'\n",
        "skeleton = pix2pix(cpdir_ske)\n",
        "skeleton.loadcp()"
      ],
      "metadata": {
        "id": "YUiUuoMabuPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload Files"
      ],
      "metadata": {
        "id": "EbKw4Q7s4VFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tab under will prompt to upload local files,\n",
        "Support Format:\n",
        "  most image format\n",
        "  MP4, AVI\n",
        "  zip"
      ],
      "metadata": {
        "id": "F0k0dfCC4Z48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "img_suffix = ('.jpg', '.png', '.ico', '.gif', '.jpeg','.jfif')\n",
        "vid_suffix = ('.avi','.mp4')\n",
        "filenames = uploaded.keys()\n",
        "\n",
        "for filename in filenames:\n",
        "  if filename.endswith('.zip'):\n",
        "    !unzip {filename} -d \"data\"\n",
        "    os.remove(filename)\n",
        "  elif filename.endswith(img_suffix) or filename.endswith(vid_suffix):\n",
        "    os.makedirs(\"data/\", exist_ok=True)\n",
        "    shutil.move(filename, \"data/\")"
      ],
      "metadata": {
        "id": "zi3cgsVouuDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process & Download"
      ],
      "metadata": {
        "id": "D1PLjoEK7y0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_names = sorted([n for n in os.listdir(imgdr) if not n.startswith('.')])\n",
        "\n",
        "outdr1 = 'out_seg'\n",
        "!mkdir -p {outdr1}\n",
        "outdr2 = 'out_ske'\n",
        "!mkdir -p {outdr2}\n",
        "audiofile = '_sound.mp3'\n",
        "\n",
        "for image_name in tqdm.tqdm(image_names):\n",
        "  image_path = os.path.join(imgdr, image_name)\n",
        "  #loop through for gif\n",
        "  if image_path.endswith('.gif'):\n",
        "    image = Image.open(image_path)\n",
        "    image.seek(0)\n",
        "    mask_frames = []\n",
        "    ske_frames = []\n",
        "    durations = []\n",
        "    for frame in ImageSequence.Iterator(image):\n",
        "        durations.append(image.info['duration'])\n",
        "        frame = frame.convert('RGB')\n",
        "        tfframe = tf.convert_to_tensor(np.array(frame))\n",
        "        mframe = Infer(prep.img_seg, masked.generator, tfframe, True)\n",
        "        sframe = Infer(prep.img_seg, skeleton.generator, tfframe, False)\n",
        "\n",
        "        mask_frames.append(mframe)\n",
        "        ske_frames.append(sframe)\n",
        "    mask_frames[0].save(os.path.join(outdr1, image_name),\n",
        "        save_all=True,\n",
        "        append_images=mask_frames[1:],\n",
        "        duration=durations,\n",
        "        loop=0)\n",
        "    ske_frames[0].save(os.path.join(outdr2, image_name),\n",
        "        save_all=True,\n",
        "        append_images=ske_frames[1:],\n",
        "        duration=durations,\n",
        "        loop=0)\n",
        "  #simple image process\n",
        "  elif image_path.endswith(img_suffix):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.io.decode_image(image)\n",
        "    channel = image.shape[-1]\n",
        "    if channel == 1:\n",
        "      image = tf.image.grayscale_to_rgb(image)\n",
        "    elif channel == 4:\n",
        "      image = tfio.experimental.color.rgba_to_rgb(image)\n",
        "    elif channel == 2:\n",
        "      print(\"Stop, Get Some Help, Only RGB, RGBA, Greyscale\")\n",
        "      continue\n",
        "    maskout = Infer(prep.img_seg, masked.generator, image, True)\n",
        "    skeletonout = Infer(prep.img_seg, skeleton.generator, image, False)\n",
        "    maskout.save(os.path.join(outdr1, image_name))\n",
        "    skeletonout.save(os.path.join(outdr2, image_name))\n",
        "  #loop through video frames\n",
        "  elif image_path.endswith(vid_suffix):\n",
        "    print('video',image_path)\n",
        "    video = cv2.VideoCapture(image_path)\n",
        "    if not video.isOpened():\n",
        "      print('video does not exist')\n",
        "      continue\n",
        "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "    frame_num = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_width = 256*3\n",
        "    frame_height = 256\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    name1 = os.path.join(outdr1, image_name)\n",
        "    name2 = os.path.join(outdr2, image_name)\n",
        "    video_writer1 = cv2.VideoWriter(name1,fourcc,fps,(frame_width,frame_height))\n",
        "    video_writer2 = cv2.VideoWriter(name2,fourcc,fps,(frame_width,frame_height))\n",
        "    print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "    counter =0\n",
        "    while True:\n",
        "      ret, frame = video.read()\n",
        "      if ret == True:\n",
        "          tfframe= tf.convert_to_tensor(frame)\n",
        "          mframe = Infer(prep.img_seg, masked.generator, tfframe, True)\n",
        "          sframe = Infer(prep.img_seg, skeleton.generator, tfframe, False)\n",
        "          m_cv2 = cv2.cvtColor(np.array(mframe), cv2.COLOR_RGB2BGR)\n",
        "          s_cv2 = cv2.cvtColor(np.array(sframe), cv2.COLOR_RGB2BGR)\n",
        "          video_writer1.write(m_cv2)\n",
        "          video_writer2.write(s_cv2)\n",
        "          counter +=1\n",
        "      if ret == False:\n",
        "          break\n",
        "    video.release()\n",
        "    video_writer1.release()\n",
        "    video_writer2.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "!zip -r file.zip {outdr1} {outdr2}\n",
        "files.download('file.zip')"
      ],
      "metadata": {
        "id": "FzS2ywyItq4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf {outdr1} {outdr2} {imgdr}"
      ],
      "metadata": {
        "id": "hxfIuAKuVQA3"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}